{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHIX4UiJdANv"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost scikit-learn pandas numpy matplotlib --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Config"
      ],
      "metadata": {
        "id": "3avjIf3qfMQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import xgboost as xgb\n",
        "\n",
        "TRAIN_CSV = \"/content/Heart_Attack_training_dataset.csv\"\n",
        "TEST_CSV = \"/content/Hear_Attack_evaluation_dataset.csv\"\n",
        "TEAM_CODE = \"EM06\"\n",
        "TEAM_NAME = \"Sindorai\"\n",
        "OUT_PRED_CSV = f\"{TEAM_CODE}_{TEAM_NAME}_Task1_Predictions.csv\"\n",
        "\n",
        "TARGET_COL = \"heart_attack_risk\"\n",
        "ID_COL = \"patient_id\""
      ],
      "metadata": {
        "id": "ujgIPKUqfJNG"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Functions"
      ],
      "metadata": {
        "id": "tIGi_OI2fZni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_bp(df):\n",
        "    sys_vals, dia_vals = [], []\n",
        "    for val in df[\"bp\"].astype(str).tolist():\n",
        "        if \"/\" in val:\n",
        "            try:\n",
        "                s, d = val.split(\"/\")\n",
        "                sys_vals.append(float(s))\n",
        "                dia_vals.append(float(d))\n",
        "            except:\n",
        "                sys_vals.append(np.nan)\n",
        "                dia_vals.append(np.nan)\n",
        "        else:\n",
        "            sys_vals.append(np.nan)\n",
        "            dia_vals.append(np.nan)\n",
        "    df[\"bp_sys\"] = sys_vals\n",
        "    df[\"bp_dia\"] = dia_vals\n",
        "    return df.drop(columns=[\"bp\"])\n",
        "\n",
        "# Load\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "print(\"Original shapes:\")\n",
        "print(f\"Train: {train_df.shape}, Test: {test_df.shape}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(train_df[TARGET_COL].value_counts(normalize=True))\n",
        "\n",
        "# Parse BP\n",
        "train_df = parse_bp(train_df)\n",
        "test_df = parse_bp(test_df)\n"
      ],
      "metadata": {
        "id": "_2ZDRlMFfSRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3976d5-3072-4dfd-d653-03070cf6437b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes:\n",
            "Train: (7963, 26), Test: (800, 25)\n",
            "\n",
            "Class distribution:\n",
            "heart_attack_risk\n",
            "0    0.656034\n",
            "1    0.343966\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "5AtDa5fKwLkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVED: country, continent, hemisphere (likely noise)\n",
        "# KEPT: Only medically relevant features\n",
        "\n",
        "# Binary categorical (keep as 0/1)\n",
        "binary_cats = [\"sex\", \"diabetes\", \"family_history\", \"smoking\",\n",
        "               \"obesity\", \"alcohol\", \"prev_heart_prob\", \"med_use\"]\n",
        "\n",
        "# Ordinal categorical (needs proper ordering)\n",
        "ordinal_cats = [\"diet\"]  # Poor < Average < Healthy\n",
        "\n",
        "# Numeric features\n",
        "num_cols = [\"age\", \"chol\", \"hr\", \"exercise_hr_wk\", \"stress_lvl\",\n",
        "            \"sedentary_hr\", \"income\", \"bmi\", \"triglycerides\",\n",
        "            \"phys_act_days\", \"sleep_hr\", \"bp_sys\", \"bp_dia\"]\n"
      ],
      "metadata": {
        "id": "E0--az--wKuD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diet_mapping = {\n",
        "    'Poor': 0,\n",
        "    'Average': 1,\n",
        "    'Healthy': 2,\n",
        "    'Unhealthy': 0,  # Treat as Poor\n",
        "    np.nan: 1  # Default to Average\n",
        "}\n",
        "\n",
        "for df in [train_df, test_df]:\n",
        "    df['diet'] = df['diet'].map(diet_mapping).fillna(1)\n",
        "\n",
        "for col in binary_cats:\n",
        "    for df in [train_df, test_df]:\n",
        "        # Handle any text values\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col] = df[col].map({'Male': 1, 'Female': 0,\n",
        "                                   'Yes': 1, 'No': 0,\n",
        "                                   '1': 1, '0': 0,\n",
        "                                   1: 1, 0: 0})\n",
        "        # Fill missing with mode\n",
        "        mode_val = train_df[col].mode()[0] if len(train_df[col].mode()) > 0 else 0\n",
        "        df[col].fillna(mode_val, inplace=True)\n",
        "        df[col] = df[col].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "for col in num_cols:\n",
        "    median_val = train_df[col].median()\n",
        "    train_df[col].fillna(median_val, inplace=True)\n",
        "    test_df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# Scale numeric\n",
        "scaler = StandardScaler()\n",
        "train_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(train_df[num_cols]),\n",
        "    columns=num_cols,\n",
        "    index=train_df.index\n",
        ")\n",
        "test_scaled = pd.DataFrame(\n",
        "    scaler.transform(test_df[num_cols]),\n",
        "    columns=num_cols,\n",
        "    index=test_df.index\n",
        ")\n",
        "\n",
        "\n",
        "all_features = num_cols + binary_cats + ordinal_cats\n",
        "\n",
        "X = pd.concat([\n",
        "    train_scaled,\n",
        "    train_df[binary_cats + ordinal_cats].reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "X_test_final = pd.concat([\n",
        "    test_scaled,\n",
        "    test_df[binary_cats + ordinal_cats].reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "y = train_df[TARGET_COL]\n",
        "\n",
        "print(f\"\\nFinal features: {X.shape[1]}\")\n",
        "print(f\"Features used: {list(X.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58XrxHxBwR1V",
        "outputId": "0cc2aca9-f0de-46e1-906d-d6d0e1670d17"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final features: 22\n",
            "Features used: ['age', 'chol', 'hr', 'exercise_hr_wk', 'stress_lvl', 'sedentary_hr', 'income', 'bmi', 'triglycerides', 'phys_act_days', 'sleep_hr', 'bp_sys', 'bp_dia', 'sex', 'diabetes', 'family_history', 'smoking', 'obesity', 'alcohol', 'prev_heart_prob', 'med_use', 'diet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader"
      ],
      "metadata": {
        "id": "CwMDpx0pffsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain: {X_train.shape}, Val: {X_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djJ2Eifyfcuj",
        "outputId": "9776ec45-e541-4a20-f12d-8784b698a2b2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train: (6370, 22), Val: (1593, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  XGBoost Model"
      ],
      "metadata": {
        "id": "uSC9GwbxfqRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training XGBoost\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "scale_pos = (len(y_train) - sum(y_train)) / sum(y_train)\n",
        "print(f\"Scale pos weight: {scale_pos:.2f}\")\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": \"auc\",\n",
        "    \"eta\": 0.05,\n",
        "    \"max_depth\": 5,\n",
        "    \"min_child_weight\": 2,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"gamma\": 0.5,\n",
        "    \"reg_alpha\": 0.1,\n",
        "    \"reg_lambda\": 1,\n",
        "    \"scale_pos_weight\": scale_pos,\n",
        "    \"seed\": 42\n",
        "}\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
        "\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=500,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=50\n",
        ")\n",
        "\n",
        "print(f\"\\nBest iteration: {model.best_iteration}\")\n",
        "print(f\"Best val AUC: {model.best_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GGN8mDbfrOB",
        "outputId": "9ec32434-fad5-48c5-9346-8824544d1448"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Training XGBoost\n",
            "==================================================\n",
            "Scale pos weight: 1.91\n",
            "[0]\ttrain-auc:0.56997\tval-auc:0.49475\n",
            "[50]\ttrain-auc:0.82163\tval-auc:0.49670\n",
            "[73]\ttrain-auc:0.85213\tval-auc:0.49743\n",
            "\n",
            "Best iteration: 24\n",
            "Best val AUC: 0.5137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "9NompupYfuFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_probs = model.predict(dval)\n",
        "val_preds = (val_probs >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Validation Metrics (threshold=0.5)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"AUC      : {roc_auc_score(y_val, val_probs):.4f}\")\n",
        "print(f\"Accuracy : {accuracy_score(y_val, val_preds):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_val, val_preds):.4f}\")\n",
        "print(f\"Recall   : {recall_score(y_val, val_preds):.4f}\")\n",
        "print(f\"F1       : {f1_score(y_val, val_preds):.4f}\")\n",
        "\n",
        "print(f\"\\nVal prob distribution:\")\n",
        "print(f\"  Min: {val_probs.min():.4f}\")\n",
        "print(f\"  Max: {val_probs.max():.4f}\")\n",
        "print(f\"  Mean: {val_probs.mean():.4f}\")\n",
        "print(f\"  Std: {val_probs.std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cwckPkEfyNX",
        "outputId": "70d44916-d446-48e3-b6ef-1d085172d969"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Validation Metrics (threshold=0.5)\n",
            "==================================================\n",
            "AUC      : 0.4976\n",
            "Accuracy : 0.5229\n",
            "Precision: 0.3455\n",
            "Recall   : 0.4325\n",
            "F1       : 0.3841\n",
            "\n",
            "Val prob distribution:\n",
            "  Min: 0.2376\n",
            "  Max: 0.7236\n",
            "  Mean: 0.4922\n",
            "  Std: 0.0616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "e7NEnwjLw3W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = model.get_score(importance_type='gain')\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': importance.keys(),\n",
        "    'importance': importance.values()\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Top 10 Most Important Features\")\n",
        "print(\"=\"*50)\n",
        "print(importance_df.head(10).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U4Ewgm6w2tg",
        "outputId": "cf545727-3f99-43b0-a6d2-93eb54fa6235"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Top 10 Most Important Features\n",
            "==================================================\n",
            "       feature  importance\n",
            "    stress_lvl    8.465065\n",
            "           bmi    8.146898\n",
            "        income    7.559237\n",
            "exercise_hr_wk    7.554323\n",
            "        bp_sys    7.547535\n",
            " triglycerides    7.508315\n",
            "        bp_dia    7.496134\n",
            "  sedentary_hr    7.494213\n",
            "          chol    7.362843\n",
            "            hr    7.289238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold optimization for recall"
      ],
      "metadata": {
        "id": "KJCaucLejwX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Optimizing Threshold for Recall\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_recall = 0\n",
        "best_threshold = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "# Try different thresholds and track metrics\n",
        "threshold_results = []\n",
        "for thr in np.linspace(0.3, 0.7, 41):\n",
        "    preds = (val_probs >= thr).astype(int)\n",
        "    rec = recall_score(y_val, preds)\n",
        "    f1 = f1_score(y_val, preds)\n",
        "    prec = precision_score(y_val, preds, zero_division=0)\n",
        "\n",
        "    threshold_results.append({\n",
        "        'threshold': thr,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'precision': prec\n",
        "    })\n",
        "\n",
        "    # Optimize: High recall but keep F1 reasonable\n",
        "    if rec > best_recall and f1 > 0.40:\n",
        "        best_recall = rec\n",
        "        best_threshold = thr\n",
        "        best_f1 = f1\n",
        "\n",
        "# Show top options\n",
        "results_df = pd.DataFrame(threshold_results).sort_values('recall', ascending=False)\n",
        "print(\"\\nTop 5 thresholds by recall:\")\n",
        "print(results_df.head(5).to_string(index=False))\n",
        "\n",
        "print(f\"\\nSelected threshold: {best_threshold:.3f}\")\n",
        "optimized_preds = (val_probs >= best_threshold).astype(int)\n",
        "print(f\"  Recall:    {recall_score(y_val, optimized_preds):.4f}\")\n",
        "print(f\"  F1:        {f1_score(y_val, optimized_preds):.4f}\")\n",
        "print(f\"  Precision: {precision_score(y_val, optimized_preds):.4f}\")\n",
        "print(f\"  Accuracy:  {accuracy_score(y_val, optimized_preds):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aticrZ_kjxAG",
        "outputId": "852d9a9b-8686-4e1d-d367-cda4fce3aaf7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Optimizing Threshold for Recall\n",
            "==================================================\n",
            "\n",
            "Top 5 thresholds by recall:\n",
            " threshold   recall       f1  precision\n",
            "      0.30 0.998175 0.512172   0.344458\n",
            "      0.31 0.998175 0.512412   0.344675\n",
            "      0.32 0.998175 0.512893   0.345110\n",
            "      0.33 0.998175 0.513133   0.345328\n",
            "      0.34 0.996350 0.513158   0.345570\n",
            "\n",
            "Selected threshold: 0.300\n",
            "  Recall:    0.9982\n",
            "  F1:        0.5122\n",
            "  Precision: 0.3445\n",
            "  Accuracy:  0.3459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Prediction"
      ],
      "metadata": {
        "id": "f2EpYFrPj0pA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Final Prediction on Test\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "dtrain_full = xgb.DMatrix(X, label=y)\n",
        "dtest = xgb.DMatrix(X_test_final)\n",
        "\n",
        "final_model = xgb.train(params, dtrain_full, num_boost_round=model.best_iteration)\n",
        "test_probs = final_model.predict(dtest)\n",
        "\n",
        "print(f\"Test prob distribution:\")\n",
        "print(f\"  Min: {test_probs.min():.4f}\")\n",
        "print(f\"  Max: {test_probs.max():.4f}\")\n",
        "print(f\"  Mean: {test_probs.mean():.4f}\")\n",
        "print(f\"  Std: {test_probs.std():.4f}\")\n",
        "\n",
        "prob_spread = test_probs.max() - test_probs.min()\n",
        "print(f\"  Spread: {prob_spread:.4f}\")\n",
        "\n",
        "# Decision logic\n",
        "if prob_spread > 0.15:\n",
        "    # Model has reasonable confidence\n",
        "    test_preds = (test_probs >= best_threshold).astype(int)\n",
        "    print(f\"\\nUsing optimized threshold: {best_threshold:.3f}\")\n",
        "\n",
        "    # Safety check - if predicting too many positives, adjust\n",
        "    predicted_pos_rate = test_preds.mean()\n",
        "    val_pos_rate = y_val.mean()\n",
        "\n",
        "    print(f\"Predicted positive rate: {predicted_pos_rate:.2%}\")\n",
        "    print(f\"Validation positive rate: {val_pos_rate:.2%}\")\n",
        "\n",
        "    # If predicting >80% positive, use more conservative threshold\n",
        "    if predicted_pos_rate > 0.8:\n",
        "        print(\"Warning: Predicting too many positives, adjusting threshold\")\n",
        "        # Find threshold that gives reasonable positive rate\n",
        "        sorted_probs = np.sort(test_probs)\n",
        "        target_positives = int(len(test_probs) * min(val_pos_rate * 1.2, 0.6))\n",
        "        adjusted_threshold = sorted_probs[-target_positives]\n",
        "        test_preds = (test_probs >= adjusted_threshold).astype(int)\n",
        "        print(f\"Adjusted threshold: {adjusted_threshold:.3f}\")\n",
        "        print(f\"New positive rate: {test_preds.mean():.2%}\")\n",
        "\n",
        "else:\n",
        "    # Model still guessing - use safer approach\n",
        "    print(f\"\\nWarning: Low spread ({prob_spread:.4f}), using distribution matching\")\n",
        "    val_pos_rate = y_val.mean()\n",
        "    num_positive = int(len(test_probs) * val_pos_rate)\n",
        "    test_preds = np.zeros(len(test_probs), dtype=int)\n",
        "    top_indices = np.argsort(test_probs)[-num_positive:]\n",
        "    test_preds[top_indices] = 1\n",
        "\n",
        "# Save\n",
        "submission = pd.DataFrame({\n",
        "    ID_COL: test_df[ID_COL],\n",
        "    TARGET_COL: test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(OUT_PRED_CSV, index=False)\n",
        "print(f\"\\nSaved: {OUT_PRED_CSV}\")\n",
        "print(f\"Predictions: Class 0={np.sum(test_preds==0)}, Class 1={np.sum(test_preds==1)}\")\n",
        "print(f\"Positive rate: {test_preds.mean():.2%}\")"
      ],
      "metadata": {
        "id": "u-bEU8goj3Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1f5328-0f39-4b30-ff44-912ec95a6082"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Final Prediction on Test\n",
            "==================================================\n",
            "Test prob distribution:\n",
            "  Min: 0.3550\n",
            "  Max: 0.6005\n",
            "  Mean: 0.4951\n",
            "  Std: 0.0264\n",
            "  Spread: 0.2456\n",
            "\n",
            "Using optimized threshold: 0.300\n",
            "Predicted positive rate: 100.00%\n",
            "Validation positive rate: 34.40%\n",
            "Warning: Predicting too many positives, adjusting threshold\n",
            "Adjusted threshold: 0.500\n",
            "New positive rate: 41.25%\n",
            "\n",
            "Saved: EM06_Sindorai_Task1_Predictions.csv\n",
            "Predictions: Class 0=470, Class 1=330\n",
            "Positive rate: 41.25%\n"
          ]
        }
      ]
    }
  ]
}