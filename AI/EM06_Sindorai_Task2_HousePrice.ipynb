{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction - Team Sindorai (EM06)\n",
    "\n",
    "This notebook implements a machine learning regression model to predict house prices based on various features.\n",
    "\n",
    "## Team Information\n",
    "- **Team Name:** Sindorai\n",
    "- **Team Code:** EM06\n",
    "- **Task:** Task 2 - House Price Prediction (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")\n",
    "print(f\"\\nTraining dataset columns: {list(train_df.columns)}\")\n",
    "print(f\"\\nTest dataset columns: {list(test_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the training dataset\n",
    "print(\"Training Dataset Info:\")\n",
    "print(train_df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the training dataset\n",
    "print(\"Statistical Summary:\")\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in training dataset:\")\n",
    "missing_train = train_df.isnull().sum()\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "missing_test = test_df.isnull().sum()\n",
    "print(missing_test[missing_test > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_df['target_price'], bins=50, alpha=0.7)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log(train_df['target_price']), bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Log House Prices')\n",
    "plt.xlabel('Log Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(f\"Mean: ${train_df['target_price'].mean():,.2f}\")\n",
    "print(f\"Median: ${train_df['target_price'].median():,.2f}\")\n",
    "print(f\"Min: ${train_df['target_price'].min():,.2f}\")\n",
    "print(f\"Max: ${train_df['target_price'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_columns = train_df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = train_df[numeric_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show features most correlated with target price\n",
    "price_corr = correlation_matrix['target_price'].abs().sort_values(ascending=False)\n",
    "print(\"Features most correlated with price:\")\n",
    "print(price_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "# Handle missing values in renovated_year (treat 0 as \"never renovated\")\n",
    "# We can create a binary feature for whether the house was renovated\n",
    "train_processed['is_renovated'] = (train_processed['renovated_year'] > 0).astype(int)\n",
    "test_processed['is_renovated'] = (test_processed['renovated_year'] > 0).astype(int)\n",
    "\n",
    "# Fill missing renovated_year with 0\n",
    "train_processed['renovated_year'].fillna(0, inplace=True)\n",
    "test_processed['renovated_year'].fillna(0, inplace=True)\n",
    "\n",
    "# Create age feature\n",
    "current_year = 2025\n",
    "train_processed['house_age'] = current_year - train_processed['built_year']\n",
    "test_processed['house_age'] = current_year - test_processed['built_year']\n",
    "\n",
    "# Create years since renovation feature\n",
    "train_processed['years_since_renovation'] = np.where(\n",
    "    train_processed['renovated_year'] > 0,\n",
    "    current_year - train_processed['renovated_year'],\n",
    "    train_processed['house_age']\n",
    ")\n",
    "test_processed['years_since_renovation'] = np.where(\n",
    "    test_processed['renovated_year'] > 0,\n",
    "    current_year - test_processed['renovated_year'],\n",
    "    test_processed['house_age']\n",
    ")\n",
    "\n",
    "# Create price per square foot features using neighbor data\n",
    "train_processed['price_per_sqft'] = train_processed['target_price'] / train_processed['living_area']\n",
    "# For test set, we'll estimate this later\n",
    "\n",
    "print(\"Feature engineering completed.\")\n",
    "print(f\"New features created: {['is_renovated', 'house_age', 'years_since_renovation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle sale_date - extract useful temporal features\n",
    "train_processed['sale_date'] = pd.to_datetime(train_processed['sale_date'])\n",
    "test_processed['sale_date'] = pd.to_datetime(test_processed['sale_date'])\n",
    "\n",
    "train_processed['sale_year'] = train_processed['sale_date'].dt.year\n",
    "train_processed['sale_month'] = train_processed['sale_date'].dt.month\n",
    "train_processed['sale_quarter'] = train_processed['sale_date'].dt.quarter\n",
    "\n",
    "test_processed['sale_year'] = test_processed['sale_date'].dt.year\n",
    "test_processed['sale_month'] = test_processed['sale_date'].dt.month\n",
    "test_processed['sale_quarter'] = test_processed['sale_date'].dt.quarter\n",
    "\n",
    "# Drop the original sale_date column as we've extracted the useful parts\n",
    "train_processed.drop('sale_date', axis=1, inplace=True)\n",
    "test_processed.drop('sale_date', axis=1, inplace=True)\n",
    "\n",
    "print(\"Temporal features extracted from sale_date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for modeling (exclude target and ID)\n",
    "feature_columns = [col for col in train_processed.columns if col not in ['house_id', 'target_price', 'price_per_sqft']]\n",
    "\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['target_price']\n",
    "X_test = test_processed[feature_columns]\n",
    "\n",
    "print(f\"Features for modeling: {feature_columns}\")\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=1.0, random_state=42),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse, train_mae, train_r2 = calculate_metrics(y_train, y_train_pred)\n",
    "    val_rmse, val_mae, val_r2 = calculate_metrics(y_val, y_val_pred)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_mae': val_mae,\n",
    "        'val_r2': val_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  Training RMSE: {train_rmse:,.2f}\")\n",
    "    print(f\"  Validation RMSE: {val_rmse:,.2f}\")\n",
    "    print(f\"  Training MAE: {train_mae:,.2f}\")\n",
    "    print(f\"  Validation MAE: {val_mae:,.2f}\")\n",
    "    print(f\"  Training R²: {train_r2:.4f}\")\n",
    "    print(f\"  Validation R²: {val_r2:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame for comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(model_results.keys()),\n",
    "    'Train_RMSE': [model_results[name]['train_rmse'] for name in model_results.keys()],\n",
    "    'Val_RMSE': [model_results[name]['val_rmse'] for name in model_results.keys()],\n",
    "    'Train_MAE': [model_results[name]['train_mae'] for name in model_results.keys()],\n",
    "    'Val_MAE': [model_results[name]['val_mae'] for name in model_results.keys()],\n",
    "    'Train_R2': [model_results[name]['train_r2'] for name in model_results.keys()],\n",
    "    'Val_R2': [model_results[name]['val_r2'] for name in model_results.keys()]\n",
    "})\n",
    "\n",
    "# Sort by validation RMSE (lower is better)\n",
    "results_df = results_df.sort_values('Val_RMSE')\n",
    "print(\"Model Comparison Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best performing model for tuning\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "\n",
    "# Hyperparameter tuning for the best model\n",
    "if 'Random Forest' in best_model_name:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestRegressor(random_state=42)\n",
    "elif 'Gradient Boosting' in best_model_name:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = GradientBoostingRegressor(random_state=42)\n",
    "else:\n",
    "    # For other models, use the original\n",
    "    base_model = model_results[best_model_name]['model']\n",
    "    param_grid = None\n",
    "\n",
    "if param_grid:\n",
    "    print(f\"Performing hyperparameter tuning for {best_model_name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        base_model, \n",
    "        param_grid, \n",
    "        cv=5, \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "else:\n",
    "    best_model = base_model\n",
    "    print(f\"Using original {best_model_name} model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model on the full training set\n",
    "print(\"Training final model on complete training dataset...\")\n",
    "final_model = best_model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the full training set for evaluation\n",
    "y_train_final_pred = final_model.predict(X)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_rmse, final_mae, final_r2 = calculate_metrics(y, y_train_final_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"FINAL MODEL PERFORMANCE: {type(final_model).__name__}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"RMSE (Root Mean Squared Error): {final_rmse:,.2f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {final_mae:,.2f}\")\n",
    "print(f\"R² Score: {final_r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store metrics for screenshot\n",
    "final_metrics = {\n",
    "    'RMSE': final_rmse,\n",
    "    'MAE': final_mae,\n",
    "    'R2': final_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs predicted prices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y, y_train_final_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y - y_train_final_pred\n",
    "plt.scatter(y_train_final_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if the model supports it)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "else:\n",
    "    print(\"Feature importance not available for this model type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Predictions for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "print(\"Generating predictions for test dataset...\")\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'house_id': test_processed['house_id'],\n",
    "    'predicted_price': test_predictions\n",
    "})\n",
    "\n",
    "print(f\"Generated {len(submission_df)} predictions.\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"Mean predicted price: ${submission_df['predicted_price'].mean():,.2f}\")\n",
    "print(f\"Median predicted price: ${submission_df['predicted_price'].median():,.2f}\")\n",
    "print(f\"Min predicted price: ${submission_df['predicted_price'].min():,.2f}\")\n",
    "print(f\"Max predicted price: ${submission_df['predicted_price'].max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to CSV file\n",
    "submission_filename = 'EM06_Sindorai_Task2_Predictions.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"Predictions saved to {submission_filename}\")\n",
    "\n",
    "# Verify the file was saved correctly\n",
    "verification_df = pd.read_csv(submission_filename)\n",
    "print(f\"\\nVerification - File contains {len(verification_df)} rows\")\n",
    "print(f\"Columns: {list(verification_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HOUSE PRICE PREDICTION MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Team: Sindorai (EM06)\")\n",
    "print(f\"Final Model: {type(final_model).__name__}\")\n",
    "print(f\"Training Dataset Size: {len(train_df)} houses\")\n",
    "print(f\"Test Dataset Size: {len(test_df)} houses\")\n",
    "print(f\"Number of Features: {len(feature_columns)}\")\n",
    "print(\"\\nFINAL PERFORMANCE METRICS:\")\n",
    "print(f\"  RMSE: {final_metrics['RMSE']:,.2f}\")\n",
    "print(f\"  MAE:  {final_metrics['MAE']:,.2f}\")\n",
    "print(f\"  R²:   {final_metrics['R2']:.4f}\")\n",
    "print(\"\\nOUTPUT FILES GENERATED:\")\n",
    "print(f\"  1. Notebook: EM06_Sindorai_Task2_HousePrice.ipynb\")\n",
    "print(f\"  2. Predictions: EM06_Sindorai_Task2_Predictions.csv\")\n",
    "print(f\"  3. Metrics Screenshot: EM06_Sindorai_Task2_Metrics.png (to be captured)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}